{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\n\nimport numpy as np\nimport pandas as pd\nimport missingno as msno\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom tqdm.notebook import tqdm\nfrom glob import glob\n\nseed = 42\npd.set_option('display.max_colwidth', None)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-04T14:31:49.891221Z","iopub.execute_input":"2022-12-04T14:31:49.891941Z","iopub.status.idle":"2022-12-04T14:31:51.921515Z","shell.execute_reply.started":"2022-12-04T14:31:49.891852Z","shell.execute_reply":"2022-12-04T14:31:51.920556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything()\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Currently using \"{device.upper()}\" device.')","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:51.923261Z","iopub.execute_input":"2022-12-04T14:31:51.923839Z","iopub.status.idle":"2022-12-04T14:31:51.98947Z","shell.execute_reply.started":"2022-12-04T14:31:51.923802Z","shell.execute_reply":"2022-12-04T14:31:51.988417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### External data EDA","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/isic-2019/ISIC_2019_Training_Metadata.csv\").drop(\"lesion_id\", axis=1)\nim_df = pd.read_csv(\"/kaggle/input/isic-2019/ISIC_2019_Training_GroundTruth.csv\").drop(\"UNK\", axis=1)\nim_df[\"labels\"] = im_df.iloc[:, 1:].idxmax(axis=1)\n\ndf = df.join(im_df.set_index(\"image\"), on=[\"image\"]).drop([\"MEL\", \"NV\", \"BCC\", \"AK\", \"DF\", \"VASC\", \"SCC\", \"BKL\"], axis=1)\ndf = df[~df[\"image\"].str.contains(\"downsampled\")]\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:52.087803Z","iopub.execute_input":"2022-12-04T14:31:52.088081Z","iopub.status.idle":"2022-12-04T14:31:52.27006Z","shell.execute_reply.started":"2022-12-04T14:31:52.088055Z","shell.execute_reply":"2022-12-04T14:31:52.269039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(df, figsize=(10,6))","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:53.189092Z","iopub.execute_input":"2022-12-04T14:31:53.189696Z","iopub.status.idle":"2022-12-04T14:31:53.602307Z","shell.execute_reply.started":"2022-12-04T14:31:53.18966Z","shell.execute_reply":"2022-12-04T14:31:53.601031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.heatmap(df, figsize=(10,6))","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:53.761498Z","iopub.execute_input":"2022-12-04T14:31:53.761846Z","iopub.status.idle":"2022-12-04T14:31:54.080923Z","shell.execute_reply.started":"2022-12-04T14:31:53.761815Z","shell.execute_reply":"2022-12-04T14:31:54.080066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.histplot(x=\"age_approx\", hue=\"labels\", data=df, kde=True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:54.315237Z","iopub.execute_input":"2022-12-04T14:31:54.315976Z","iopub.status.idle":"2022-12-04T14:31:55.504022Z","shell.execute_reply.started":"2022-12-04T14:31:54.31592Z","shell.execute_reply":"2022-12-04T14:31:55.503091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(14,6))\nsns.countplot(x=\"anatom_site_general\", hue=\"labels\", data=df)\nplt.legend(loc=\"upper right\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:55.506047Z","iopub.execute_input":"2022-12-04T14:31:55.506447Z","iopub.status.idle":"2022-12-04T14:31:55.911998Z","shell.execute_reply.started":"2022-12-04T14:31:55.506408Z","shell.execute_reply":"2022-12-04T14:31:55.911042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\n\nfig = px.histogram(df, x=\"labels\", nbins=8, width=800, height=400)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:55.914018Z","iopub.execute_input":"2022-12-04T14:31:55.914373Z","iopub.status.idle":"2022-12-04T14:31:58.118029Z","shell.execute_reply.started":"2022-12-04T14:31:55.914336Z","shell.execute_reply":"2022-12-04T14:31:58.117068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"age_approx\"] = df[\"age_approx\"].fillna(df[\"age_approx\"].mean()).astype(\"int\")\ndf[\"anatom_site_general\"] = df[\"anatom_site_general\"].fillna(\"unknown\")\ndf[\"sex\"] = df[\"sex\"].fillna(\"unknown\")\n\ndf[\"age_bins\"] = pd.cut(df[\"age_approx\"], bins=[-1, 20, 40, 60, 80, 95], labels=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:58.119599Z","iopub.execute_input":"2022-12-04T14:31:58.119945Z","iopub.status.idle":"2022-12-04T14:31:58.136028Z","shell.execute_reply.started":"2022-12-04T14:31:58.119909Z","shell.execute_reply":"2022-12-04T14:31:58.135037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = {\"NV\": 0, \"MEL\": 1, \"BCC\": 1, \"BKL\": 0, \"AK\": 0, \"SCC\": 1, \"VASC\": 0, \"DF\": 0}","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:58.137863Z","iopub.execute_input":"2022-12-04T14:31:58.138711Z","iopub.status.idle":"2022-12-04T14:31:58.144318Z","shell.execute_reply.started":"2022-12-04T14:31:58.138677Z","shell.execute_reply":"2022-12-04T14:31:58.143233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nX = df[[\"age_approx\", \"anatom_site_general\", \"sex\", \"labels\"]]\nX = pd.get_dummies(X, columns=[\"anatom_site_general\", \"sex\"], drop_first=True)\nX[\"labels\"] = X[\"labels\"].map(labels)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:58.146569Z","iopub.execute_input":"2022-12-04T14:31:58.146908Z","iopub.status.idle":"2022-12-04T14:31:58.168512Z","shell.execute_reply.started":"2022-12-04T14:31:58.146872Z","shell.execute_reply":"2022-12-04T14:31:58.167712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = X.drop(\"labels\", axis=1), X[\"labels\"]\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, stratify=y, random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:58.329542Z","iopub.execute_input":"2022-12-04T14:31:58.329839Z","iopub.status.idle":"2022-12-04T14:31:58.348926Z","shell.execute_reply.started":"2022-12-04T14:31:58.329813Z","shell.execute_reply":"2022-12-04T14:31:58.34806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\ntransformer = ColumnTransformer(transformers=[(\"scaler\", StandardScaler(), [\"age_approx\",]),], remainder=\"passthrough\")\n\npipe = make_pipeline(transformer, \n                     RandomForestClassifier(n_estimators=100, max_depth=15)\n                    ).fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:59.12096Z","iopub.execute_input":"2022-12-04T14:31:59.122099Z","iopub.status.idle":"2022-12-04T14:31:59.845077Z","shell.execute_reply.started":"2022-12-04T14:31:59.122061Z","shell.execute_reply":"2022-12-04T14:31:59.844181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = pipe.predict(x_test)\n\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:31:59.890851Z","iopub.execute_input":"2022-12-04T14:31:59.891169Z","iopub.status.idle":"2022-12-04T14:32:00.015963Z","shell.execute_reply.started":"2022-12-04T14:31:59.891121Z","shell.execute_reply":"2022-12-04T14:32:00.014878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### EfficientNet Model","metadata":{}},{"cell_type":"markdown","source":"<table>\n    <tr>\n        <td>\n            <img src=https://miro.medium.com/max/1400/1*rnhgFRXetwD8PvxhZIpwIA.png width=800>\n            </td><td>\n        <img src=https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-06_at_10.45.54_PM.png width=800>\n        </td></tr>\n    </table>","metadata":{}},{"cell_type":"code","source":"# as EfficientNet (https://arxiv.org/pdf/1905.11946.pdf) has scalable architecture, define possible structures:\n# here: (width, depth, image_size, dropout_rate)\n\nparams = {\n    'efficientnet_b0': (1.0, 1.0, 224, 0.2),\n    'efficientnet_b1': (1.0, 1.1, 240, 0.2),\n    'efficientnet_b2': (1.1, 1.2, 260, 0.3),\n    'efficientnet_b3': (1.2, 1.4, 300, 0.3),\n    'efficientnet_b4': (1.4, 1.8, 380, 0.4),\n    'efficientnet_b5': (1.6, 2.2, 456, 0.4),\n    'efficientnet_b6': (1.8, 2.6, 528, 0.5),\n    'efficientnet_b7': (2.0, 3.1, 600, 0.5),\n}","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:01.687951Z","iopub.execute_input":"2022-12-04T14:32:01.688902Z","iopub.status.idle":"2022-12-04T14:32:01.696028Z","shell.execute_reply.started":"2022-12-04T14:32:01.688856Z","shell.execute_reply":"2022-12-04T14:32:01.694796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# efficientnet_b7 params\nwidth, depth, image_size, dropout = params[\"efficientnet_b7\"]","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:02.249089Z","iopub.execute_input":"2022-12-04T14:32:02.249751Z","iopub.status.idle":"2022-12-04T14:32:02.254284Z","shell.execute_reply.started":"2022-12-04T14:32:02.249718Z","shell.execute_reply":"2022-12-04T14:32:02.2533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# activation function: Swish\n\nclass Swish(nn.Module):\n    \"\"\" \n    activation function: \n    Swish allows a small number of negative weights to be propagated through, \n    while ReLU (max(0, x)) thresholds all negative weights to zero.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super(Swish, self).__init__(*args, **kwargs)\n    \n    def forward(self, x):\n        return x * torch.sigmoid(x)\n    \n    \nclass ConvBNBlock(nn.Module):\n    \"\"\" \n    basic block: zero-padded 2D convolution, followed by batch \n    normalization and Swish activation\n    \"\"\"\n    def __init__(self, in_channels, out_channels, kernel_size, *args, stride=1, groups=1, **kwargs):\n        super(ConvBNBlock, self).__init__(*args, **kwargs)\n        padding = self._get_padding(kernel_size, stride)\n        self.block = nn.Sequential(\n                nn.ZeroPad2d(padding),\n                nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding=0, groups=groups, bias=False),\n                nn.BatchNorm2d(out_channels),\n                Swish(),\n            )\n        \n    def forward(self, x):\n        return self.block(x)\n        \n    def _get_padding(self, kernel_size, stride):\n        \"\"\" add corresponding padding \"\"\"\n        p = np.maximum(kernel_size - stride, 0)\n        return [p // 2, p - p // 2, p // 2, p - p // 2]\n    \n    \nclass SqueezeExcitationBlock(nn.Module):\n    \"\"\" \n    The Squeeze-and-Excitation Block is an architectural unit designed to improve \n    the representational power of a network by enabling it to perform \n    dynamic channel-wise feature recalibration\n    \"\"\"\n    def __init__(self, in_channels, reduced_dim, *args, **kwargs):\n        super(SqueezeExcitationBlock, self).__init__(*args, **kwargs)\n        self.squeeze_excitation = nn.Sequential(\n                    nn.AdaptiveAvgPool2d(1),\n                    nn.Conv2d(in_channels, reduced_dim, kernel_size=1),\n                    Swish(),\n                    nn.Conv2d(reduced_dim, in_channels, kernel_size=1),\n                    nn.Sigmoid()\n            )\n    \n    def forward(self, x):\n        return x * self.squeeze_excitation(x)  # which is similar to swish activation\n    \n\nclass MBConvBlock(nn.Module):\n    \"\"\"\n    Inverted Linear BottleNeck layer with Depth-Wise Separable Convolution\n    implements inverted residual connection like MobileNetV2\n    \"\"\"\n    def __init__(self, in_channels, out_channels, expand_ratio, kernel_size, stride, \n                 *args, reduction_ratio=0.4, drop_connect_rate=0.2, **kwargs):\n        super(MBConvBlock, self).__init__(*args, **kwargs)\n        \n        self.drop_connect_rate = drop_connect_rate\n        self.use_residual = (in_channels == out_channels) & (stride == 1)\n        \n        assert stride in (1, 2), \"stride should be 1 or 2\"\n        assert kernel_size in (3, 5), \"kernel_size should be 3 or 5\"\n\n        hidden_dim = in_channels * expand_ratio\n        reduced_dim = np.maximum(1, int(in_channels / reduction_ratio))\n        \n        layers = []\n        if in_channels != hidden_dim:\n            layers.append(ConvBNBlock(in_channels, hidden_dim, kernel_size=1))\n\n        layers.extend([\n            ConvBNBlock(hidden_dim, hidden_dim, kernel_size, stride=stride, groups=hidden_dim),\n            SqueezeExcitationBlock(hidden_dim, reduced_dim),\n            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n        ])\n        self.conv = nn.Sequential(*layers)\n        \n    def forward(self, x):\n        if self.use_residual:\n            residual = x\n            x = self.conv(x)\n            return residual + self._drop_connections(x)\n        else:\n            return self.conv(x)\n    \n    def _drop_connections(self, x):\n        \"\"\" \n        dropout probability mask, works similarily as Dropout, except we \n        disable individual weights (i.e., set them to zero), instead of nodes\n        \"\"\"\n        if not self.training:\n            return x  # identity\n        keep_probability = 1.0 - self.drop_connect_rate\n        batch_size = x.size(0)\n        random_tensor = keep_probability + torch.rand(batch_size, 1, 1, 1, device=x.device)\n        binary_tensor = random_tensor.floor()\n        return x.div(keep_probability) * binary_tensor","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:02.98342Z","iopub.execute_input":"2022-12-04T14:32:02.983779Z","iopub.status.idle":"2022-12-04T14:32:03.008009Z","shell.execute_reply.started":"2022-12-04T14:32:02.983748Z","shell.execute_reply":"2022-12-04T14:32:03.00671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper functions\n\ndef make_divisable(value, divisor=8):\n    \"\"\" transform input value into closest divisable by divisor value \"\"\"\n    divisable_value = np.maximum(divisor, (value + divisor // 2) // divisor * divisor)\n    if divisable_value < 0.9 * value:\n        divisable_value += divisor\n    return divisable_value\n\ndef round_filters(filters, width):\n    \"\"\" return divisable number of filters \"\"\"\n    if width == 1.0:\n        return filters\n    return int(make_divisable(filters * width))  # int floor\n\ndef round_repeats(repeats, depth):\n    \"\"\" calibrate number of net blocks \"\"\"\n    if depth == 1.0:\n        return repeats\n    return int(np.ceil(depth * repeats))","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:03.535501Z","iopub.execute_input":"2022-12-04T14:32:03.535843Z","iopub.status.idle":"2022-12-04T14:32:03.542684Z","shell.execute_reply.started":"2022-12-04T14:32:03.535813Z","shell.execute_reply":"2022-12-04T14:32:03.541713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# final model\n\nclass EfficientNet(nn.Module):\n    \"\"\" Gather all blocks (it is possible to upload pretrained weights from torch hub) \"\"\"\n    def __init__(self, *args, width=1.0, depth=1.0, dropout=0.2, num_classes=10, **kwargs):\n        super(EfficientNet, self).__init__(*args, **kwargs)\n        settings = [\n           # t,  c,  n, s, k  -> expand_ratio, channels, repeats, init stride, kernel_size\n            [1,  16, 1, 1, 3],  # MBConv1_3x3, SE, 112 -> 112\n            [6,  24, 2, 2, 3],  # MBConv6_3x3, SE, 112 ->  56\n            [6,  40, 2, 2, 5],  # MBConv6_5x5, SE,  56 ->  28\n            [6,  80, 3, 2, 3],  # MBConv6_3x3, SE,  28 ->  14\n            [6, 112, 3, 1, 5],  # MBConv6_5x5, SE,  14 ->  14\n            [6, 192, 4, 2, 5],  # MBConv6_5x5, SE,  14 ->   7\n            [6, 320, 1, 1, 3]   # MBConv6_3x3, SE,   7 ->   7\n        ]\n        out_channels = round_filters(32, width)\n        layers = [ConvBNBlock(3, out_channels, kernel_size=3, stride=2),]\n        \n        in_channels = out_channels\n        for expand, channel, repeat, strid, kernel in settings:\n            out_channels = round_filters(channel, width)\n            repeats = round_repeats(repeat, depth)\n            for i in range(repeats):\n                stride = strid if i == 0 else 1  # reduce spatial dims only on first step\n                layers.extend([\n                    MBConvBlock(in_channels, out_channels, expand_ratio=expand, kernel_size=kernel, stride=stride)\n                ])\n                in_channels = out_channels\n                \n        last_channels = round_filters(1280, width)\n        layers.append(ConvBNBlock(in_channels, last_channels, kernel_size=1))\n        \n        self.features = nn.Sequential(*layers)  # name as in torch hub\n        self.classifier = nn.Sequential(\n                        nn.Dropout(p=dropout),\n                        nn.Linear(last_channels, num_classes)\n                )\n        \n        self._init_weights()\n        \n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                fan_out = m.weight.size(0)\n                init_range = 1.0 / np.sqrt(fan_out)\n                nn.init.uniform_(m.weight, -init_range, init_range)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n                    \n    def forward(self, x):\n        x = self.features(x)\n        x = x.mean(dim=[2, 3])  # flatten by mean of spatial dims\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:04.109099Z","iopub.execute_input":"2022-12-04T14:32:04.11043Z","iopub.status.idle":"2022-12-04T14:32:04.125099Z","shell.execute_reply.started":"2022-12-04T14:32:04.110387Z","shell.execute_reply":"2022-12-04T14:32:04.123954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Dataset","metadata":{}},{"cell_type":"code","source":"directory = \"/kaggle/input/isic-2019/ISIC_2019_Training_Input/ISIC_2019_Training_Input/\"\n\ndata = pd.read_csv(\"/kaggle/input/isic-2019/ISIC_2019_Training_GroundTruth.csv\").drop(\"UNK\", axis=1)\ndata[\"labels\"] = data.iloc[:, 1:].idxmax(axis=1)\ndata = data[~data[\"image\"].str.contains(\"downsampled\")]\n\nclasses_to_int = {v: i for i, v in enumerate(data.columns[1:-1])}\nint_to_classes = {i: v for i, v in enumerate(data.columns[1:-1])}\n\ndata[\"labels\"] = data[\"labels\"].map(classes_to_int)\n\nnum_classes = len(classes_to_int)\n\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:05.582264Z","iopub.execute_input":"2022-12-04T14:32:05.583324Z","iopub.status.idle":"2022-12-04T14:32:05.67769Z","shell.execute_reply.started":"2022-12-04T14:32:05.583267Z","shell.execute_reply":"2022-12-04T14:32:05.676199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"labels\"].value_counts(normalize=True)\n\n# class weights\n# random_weighted_sampler for batch composing in dataloader\n# focal loss","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:06.23941Z","iopub.execute_input":"2022-12-04T14:32:06.239817Z","iopub.status.idle":"2022-12-04T14:32:06.249961Z","shell.execute_reply.started":"2022-12-04T14:32:06.239781Z","shell.execute_reply":"2022-12-04T14:32:06.248393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# assign higher weight for minority classes in cross-entropy loss: loss gets higher when model make mistakes on minor class\nclass_weights = compute_class_weight(\"balanced\", classes=np.unique(data[\"labels\"]), y=data[\"labels\"])\n# class_weights = class_weights / class_weights.sum()  # weights normalization, unneccessary","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:10.399831Z","iopub.execute_input":"2022-12-04T14:32:10.40052Z","iopub.status.idle":"2022-12-04T14:32:10.410815Z","shell.execute_reply.started":"2022-12-04T14:32:10.400483Z","shell.execute_reply":"2022-12-04T14:32:10.4099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# augmentations\n# train: different random flips, rotations, and color shifts\ntrain_transforms = A.Compose([\n                      A.OneOf([A.HueSaturationValue(hue_shift_limit=0.2, \n                                                    sat_shift_limit=0.2, \n                                                    val_shift_limit=0.2, \n                                                    p=0.2),      \n                      A.RandomBrightnessContrast(brightness_limit=0.2, \n                                                 contrast_limit=0.2, \n                                                 p=0.5)],p=0.2),\n                      A.OneOf(\n                              [A.HorizontalFlip(p=0.5),\n                               A.VerticalFlip(p=0.5),\n                               A.RandomRotate90(p=0.5),\n                               A.Transpose(p=0.5),\n                              ], p=0.5),\n                      A.Resize(height=image_size, width=image_size, p=1),\n                      A.Cutout(num_holes=6, max_h_size=10, max_w_size=10, fill_value=0, p=0.1),\n                      A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0),\n                      ToTensorV2(p=1.0),\n                      ], p=1.0)\n\n# only resize, scale [-1, 1] and converting to tensor array[h,w,c] -> tensor[c,h,w]\nvalid_transforms = A.Compose([\n                      A.Resize(height=image_size, width=image_size, p=1),\n                      A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0),\n                      ToTensorV2(p=1.0),\n                      ], p=1.0)\n\n# inverse trasformations of a single image-tensor\ndef inverse_transforms(tensor):\n    tensor = tensor \n    if tensor.size(0) == 1 and len(tensor.shape) == 4:\n        tensor.squeeze_(0)\n    tensor = torch.clamp(tensor * 0.5 + 0.5, min=0., max=1.)\n    tensor = tensor.cpu().detach().numpy().transpose(1,2,0)\n\n    return tensor","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:10.996425Z","iopub.execute_input":"2022-12-04T14:32:10.996753Z","iopub.status.idle":"2022-12-04T14:32:11.009113Z","shell.execute_reply.started":"2022-12-04T14:32:10.996726Z","shell.execute_reply":"2022-12-04T14:32:11.008177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test = train_test_split(data, test_size=1600, stratify=data[\"labels\"], random_state=seed)\nx_valid, x_test = train_test_split(x_test, test_size=400, stratify=x_test[\"labels\"], random_state=seed)\n\nx_train.reset_index(drop=True, inplace=True)\nx_valid.reset_index(drop=True, inplace=True)\nx_test.reset_index(drop=True, inplace=True)\n\nprint(f\"train size: {len(x_train)}, valid size: {len(x_valid)}, test size: {len(x_test)}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:12.204947Z","iopub.execute_input":"2022-12-04T14:32:12.205332Z","iopub.status.idle":"2022-12-04T14:32:12.227704Z","shell.execute_reply.started":"2022-12-04T14:32:12.205301Z","shell.execute_reply":"2022-12-04T14:32:12.226602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define dataset and dataloder\n\nclass ISICDataset(Dataset):\n    def __init__(self, data, transforms):\n        self.data = data\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, ix):\n        row = self.data.loc[ix].squeeze()\n        image = Image.open(directory + row[\"image\"] + \".jpg\")\n        image = np.array(image)\n        \n        sample = {\"image\": image}\n        image = self.transforms(**sample)[\"image\"]\n        \n        label = torch.as_tensor(row[\"labels\"], dtype=torch.int64)\n        \n        return image, label\n    \n    def collate_fn(self, batch):\n        images, labels = list(zip(*batch))\n        images, labels = [[tensor[None] for tensor in subset] for subset in (images, labels)]\n        images, labels = [torch.cat(subset, dim=0).to(device) for subset in (images, labels)]\n        return images, labels","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:13.123821Z","iopub.execute_input":"2022-12-04T14:32:13.124205Z","iopub.status.idle":"2022-12-04T14:32:13.132536Z","shell.execute_reply.started":"2022-12-04T14:32:13.124172Z","shell.execute_reply":"2022-12-04T14:32:13.131527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\n\ntrain_ds = ISICDataset(x_train, train_transforms)\nvalid_ds = ISICDataset(x_valid, valid_transforms)\ntest_ds = ISICDataset(x_test, valid_transforms)\n\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=train_ds.collate_fn)\nvalid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, collate_fn=valid_ds.collate_fn)\ntest_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False, collate_fn=test_ds.collate_fn)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:14.180716Z","iopub.execute_input":"2022-12-04T14:32:14.181392Z","iopub.status.idle":"2022-12-04T14:32:14.187584Z","shell.execute_reply.started":"2022-12-04T14:32:14.181351Z","shell.execute_reply":"2022-12-04T14:32:14.186524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Objectives and metrics","metadata":{}},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    \"\"\" \n    https://github.com/AdeelH/pytorch-multi-class-focal-loss/blob/master/focal_loss.py\n    \n    Shape:\n        - x: (batch_size, C) or (batch_size, C, d1, d2, ..., dK), K > 0.\n        - y: (batch_size,) or (batch_size, d1, d2, ..., dK), K > 0.\n    \"\"\"\n    def __init__(self, *args, \n                 alpha: torch.Tensor = None, \n                 gamma: float = 2.0, \n                 reduction: str = 'mean',\n                 ignore_index: int = -100,\n                 **kwargs\n                 ):\n        \"\"\"\n        Args:\n            alpha (Tensor, optional): Weights for each class. Defaults to None.\n            gamma (float, optional): A constant, as described in the paper.\n                Defaults to 2.0\n            reduction (str, optional): 'mean', 'sum' or 'none'.\n                Defaults to 'mean'.\n            ignore_index (int, optional): class label to ignore.\n                Defaults to -100.\n        \"\"\"\n        if reduction not in ('mean', 'sum', 'none'):\n            raise ValueError(\n                'Reduction must be one of: \"mean\", \"sum\", \"none\".')\n\n        super(FocalLoss, self).__init__(*args, **kwargs)\n        self.alpha = alpha\n        self.gamma = gamma\n        self.ignore_index = ignore_index\n        self.reduction = reduction\n\n        self.nll_loss = nn.NLLLoss(\n            weight=alpha, reduction='none', ignore_index=ignore_index)\n\n    def forward(self, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n        if x.ndim > 2:\n            c = x.shape[1]  # (N, C, d1, d2, ..., dK) --> (N * d1 * ... * dK, C)\n            x = x.permute(0, *range(2, x.ndim), 1).reshape(-1, c)\n            y = y.view(-1)  # (N, d1, d2, ..., dK) --> (N * d1 * ... * dK,)\n        \n        y = y.long()\n        unignored_mask = y != self.ignore_index\n        y = y[unignored_mask]\n        if len(y) == 0:\n            return torch.tensor(0.)\n        x = x[unignored_mask]\n\n        # compute weighted cross entropy term: -alpha * log(pt) (alpha is already part of self.nll_loss)\n        log_p = F.log_softmax(x, dim=-1)\n        ce = self.nll_loss(log_p, y)\n\n        # get true class column from each row\n        all_rows = torch.arange(len(x))\n        log_pt = log_p[all_rows, y]\n\n        # compute focal term: (1 - pt)^gamma\n        pt = log_pt.exp()\n        focal_term = (1 - pt)**self.gamma\n\n        # the full loss: -alpha * ((1 - pt)^gamma) * log(pt)\n        loss = focal_term * ce\n\n        if self.reduction == 'mean':\n            loss = loss.mean()\n        elif self.reduction == 'sum':\n            loss = loss.sum()\n\n        return loss\n        \ndef calc_accuracy(y_pred, y_true):\n    return (y_true == torch.max(y_pred, 1)[1]).float().mean()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:16.197744Z","iopub.execute_input":"2022-12-04T14:32:16.198406Z","iopub.status.idle":"2022-12-04T14:32:16.224114Z","shell.execute_reply.started":"2022-12-04T14:32:16.19837Z","shell.execute_reply":"2022-12-04T14:32:16.217598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training and evaluation functions","metadata":{}},{"cell_type":"code","source":"def train_one_batch(data, model, criterion, optimizer):\n    model.train()\n    images, labels = data\n    \n    optimizer.zero_grad()\n    out = model(images)\n    loss = criterion(out, labels)\n    \n    loss.backward()\n    optimizer.step()\n    \n    accuracy = calc_accuracy(out, labels).item()\n    \n    return loss.item(), accuracy\n\n@torch.no_grad()\ndef validate_one_batch(data, model, criterion):\n    model.eval()\n    images, labels = data\n    \n    out = model(images)\n    loss = criterion(out, labels)\n    \n    accuracy = calc_accuracy(out, labels)\n    \n    return loss.item(), accuracy.item()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:18.295436Z","iopub.execute_input":"2022-12-04T14:32:18.295802Z","iopub.status.idle":"2022-12-04T14:32:18.304312Z","shell.execute_reply.started":"2022-12-04T14:32:18.295773Z","shell.execute_reply":"2022-12-04T14:32:18.303114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=3, min_delta=0, path='model.pth'):\n        self.path = path\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = None\n        self.early_stop = False\n\n    def __call__(self, val_loss, model=None, **kwargs):\n        if self.best_loss is None:\n            self.best_loss = val_loss\n        elif self.best_loss - val_loss > self.min_delta:\n            checkpoint = {'model': EfficientNet(**kwargs),\n                          'state_dict': model.state_dict(),\n                          }\n            torch.save(checkpoint, self.path)\n            print(f'Model saved to: {self.path}')\n            self.best_loss = val_loss\n            self.counter = 0\n        elif self.best_loss - val_loss < self.min_delta:\n            self.counter += 1\n            print(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n            if self.counter >= self.patience:\n                print('INFO: Early stopping')\n                self.early_stop = True","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:19.175713Z","iopub.execute_input":"2022-12-04T14:32:19.176064Z","iopub.status.idle":"2022-12-04T14:32:19.186287Z","shell.execute_reply.started":"2022-12-04T14:32:19.176034Z","shell.execute_reply":"2022-12-04T14:32:19.185018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# inverse normalized frequency of classes\nweights = np.bincount(x_train[\"labels\"])\nweights[weights == 0] = 1 \nweights = 1 / weights\nweights /= weights.sum()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:20.163913Z","iopub.execute_input":"2022-12-04T14:32:20.164285Z","iopub.status.idle":"2022-12-04T14:32:20.17154Z","shell.execute_reply.started":"2022-12-04T14:32:20.164252Z","shell.execute_reply":"2022-12-04T14:32:20.169498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Define model, loss function, optimizer, etc.","metadata":{}},{"cell_type":"code","source":"params = {\"width\": width, \n          \"depth\": depth, \n          \"dropout\": dropout, \n          \"num_classes\": num_classes\n         }\n\nmodel = EfficientNet(**params).to(device)\n\n# criterion = FocalLoss(gamma=2.0, alpha=torch.as_tensor(weights, dtype=torch.float32).to(device))  # for binary rule of thumb: alpha=0.25\n# criterion = FocalLoss(gamma=2.0, alpha=torch.as_tensor(class_weights, dtype=torch.float32).to(device))\ncriterion = FocalLoss(gamma=2.0, alpha=None)  # not weighted\n\n# weights are prety high, maybe it is hard for model to keep track for all classes, but (despite lower overall accuracy) weighted version captures more minor classes correctly\n# criterion = nn.CrossEntropyLoss(weight=torch.as_tensor(class_weights, dtype=torch.float32).to(device))\n# criterion = nn.CrossEntropyLoss()  # not weighted\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5, min_lr=1e-7)\nstopper = EarlyStopping(patience=5)","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:23.402681Z","iopub.execute_input":"2022-12-04T14:32:23.403036Z","iopub.status.idle":"2022-12-04T14:32:26.388028Z","shell.execute_reply.started":"2022-12-04T14:32:23.403005Z","shell.execute_reply":"2022-12-04T14:32:26.387035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\" Number of training parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:26.389925Z","iopub.execute_input":"2022-12-04T14:32:26.390319Z","iopub.status.idle":"2022-12-04T14:32:26.399537Z","shell.execute_reply.started":"2022-12-04T14:32:26.390283Z","shell.execute_reply":"2022-12-04T14:32:26.396846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Train","metadata":{}},{"cell_type":"code","source":"import time\n\nEPOCHS = 40  # 100 (decrease to save GPU limits...)\nprint_freq = 20\n\nfor epoch in range(1, EPOCHS+1):\n\n    train_loss, train_accs = [], []\n    for step, batch in enumerate(train_dl, 1):\n        time_1 = time.time()\n        \n        loss, accuracy = train_one_batch(batch, model, criterion, optimizer)\n\n        train_loss.append(loss)\n        train_accs.append(accuracy)\n        \n        if step % print_freq == 0:\n            print('epoch:', epoch, \n                  '\\tstep:', step, '/', len(train_dl),\n                  '\\ttrain loss:', '{:.4f}'.format(loss),\n                  '\\ttrain accuracy:','{:.4f}'.format(accuracy),\n                  '\\ttime:', '{:.4f}'.format((time.time()-time_1)*print_freq), 's')\n    \n    valid_loss, valid_accs = [], []\n    for step, batch in enumerate(tqdm(valid_dl)):\n        loss, accuracy = validate_one_batch(batch, model, criterion)\n        \n        valid_loss.append(loss)\n        valid_accs.append(accuracy)\n        \n    print('epoch:', epoch, '/', EPOCHS,\n          '\\ttrain loss:', '{:.4f}'.format(np.mean(train_loss)),\n          '\\tvalid loss:', '{:.4f}'.format(np.mean(valid_loss)),\n          '\\ttrain accuracy', '{:.4f}'.format(np.mean(train_accs)),\n          '\\tvalid accuracy', '{:.4f}'.format(np.mean(valid_accs)))\n        \n    stopper(np.mean(valid_loss), model, **params)\n    scheduler.step(np.mean(valid_loss))\n    \ntest_loss, test_accs = [], []\nfor step, batch in enumerate(tqdm(test_dl)):\n    loss, accuracy = validate_one_batch(batch, model, criterion)\n\n    test_loss.append(loss)\n    test_accs.append(accuracy)\n\nprint('\\ttest loss:', '{:.4f}'.format(np.mean(test_loss)),\n      '\\ttest accuracy', '{:.4f}'.format(np.mean(test_accs)))","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:32:29.165913Z","iopub.execute_input":"2022-12-04T14:32:29.166292Z","iopub.status.idle":"2022-12-04T14:59:13.882973Z","shell.execute_reply.started":"2022-12-04T14:32:29.166259Z","shell.execute_reply":"2022-12-04T14:59:13.879644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Load and check visually","metadata":{}},{"cell_type":"code","source":"def load_checkpoint(filepath=\"model.pth\", device=\"cuda\"):\n    checkpoint = torch.load(filepath, map_location=device)\n    model = checkpoint['model']\n    model.load_state_dict(checkpoint['state_dict'])\n    for parameter in model.parameters():\n        parameter.requires_grad = False\n\n    model.eval()\n    return model\n\nmodel = load_checkpoint()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:59:17.201121Z","iopub.execute_input":"2022-12-04T14:59:17.201854Z","iopub.status.idle":"2022-12-04T14:59:17.614047Z","shell.execute_reply.started":"2022-12-04T14:59:17.201817Z","shell.execute_reply":"2022-12-04T14:59:17.61295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef plot(num_images, model):\n    model.eval()\n    indices = np.random.choice(np.arange(len(test_ds)), size=num_images)\n    num_cols = 3\n    num_rows = int(np.ceil(num_images / num_cols))\n    \n    plt.figure(figsize=(num_rows * 3, num_cols*3))\n    for j, i in enumerate(indices, 1):\n        image, label = test_ds[i]\n        out = model(image.unsqueeze(0).to(device))\n        y_pred = int_to_classes.get(torch.max(out, 1)[1][0].item(), \"error\")\n        label = int_to_classes.get(label.item(), \"error\")\n        \n        image = inverse_transforms(image)\n        plt.subplot(num_rows, num_cols, j)\n        plt.imshow(image)\n        plt.title(f\"True label: {label}, pred: {y_pred}\")\n        plt.axis(\"off\")\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-04T14:59:19.874995Z","iopub.execute_input":"2022-12-04T14:59:19.87568Z","iopub.status.idle":"2022-12-04T14:59:19.883874Z","shell.execute_reply.started":"2022-12-04T14:59:19.875644Z","shell.execute_reply":"2022-12-04T14:59:19.882743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(num_images=12, model=model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}